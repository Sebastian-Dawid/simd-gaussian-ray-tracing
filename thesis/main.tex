\documentclass[a4paper, 11pt]{memoir}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[english]{babel}

\input{smart-thesis/style}
\input{smart-thesis/common-packages}
\input{smart-thesis/common-macros}

\usepackage{lipsum}
\usepackage[table]{xcolor}
\usepackage{minted}
\usepackage{float}

% pgfplots preamble
\usetikzlibrary{arrows.meta}
\usetikzlibrary{backgrounds}
\usepgfplotslibrary{patchplots}
\usepgfplotslibrary{fillbetween}
\pgfplotsset{%
    layers/standard/.define layer set={%
        background,axis background,axis grid,axis ticks,axis lines,axis tick labels,pre main,main,axis descriptions,axis foreground%
    }{
        grid style={/pgfplots/on layer=axis grid},%
        tick style={/pgfplots/on layer=axis ticks},%
        axis line style={/pgfplots/on layer=axis lines},%
        label style={/pgfplots/on layer=axis descriptions},%
        legend style={/pgfplots/on layer=axis descriptions},%
        title style={/pgfplots/on layer=axis descriptions},%
        colorbar style={/pgfplots/on layer=axis descriptions},%
        ticklabel style={/pgfplots/on layer=axis tick labels},%
        axis background@ style={/pgfplots/on layer=axis background},%
        3d box foreground style={/pgfplots/on layer=axis foreground},%
    },
}

\addbibresource{main.bib}

\makeglossaries
\input{glossary}

\thesistype{Bachelor Thesis}
\discipline{Computer Science}
\title{Parallel Gaussian Ray Tracing on the CPU}
\author{Sebastian Dawid}
\institution{Bielefeld University,Technical Faculty,Visual AI for Extended Reality Group}
\supervisors{Prof.\@~Dr.\@~Helge Rhodin,Prof.\@~Dr.-Ing.\@~Ralf M\"oller}

\newcommand*{\erf}{\text{erf}}

\makepagestyle{abs}

% Display the page number in the footer.
\makeevenfoot{abs}{\thepage}{}{}
\makeoddfoot{abs}{}{}{\thepage}

\begin{document}
    \frontmatter
    \smarttitle
    \newpage
    \tableofcontents*

    \clearpage
    \thispagestyle{abs}
    \abstractintoc
    \begin{abstract}
        \lipsum[1]
    \end{abstract}

    \mainmatter
    \chapter{Introduction}
    \begin{itemize}
        \item Gaussian image representations are widely used in CG/CV
        \item ray tracing is more accurate than e.g. splatting â†’  accurate intersections
        \item CPU ray tracing is slow
        \item Some machines have stronger CPUs than GPUs (e.g. integrated GPU only)
    \end{itemize}

    \chapter{Background}
    \label{ch:background}
    \section{Gaussian Ray Tracing}
    \label{sec:int_grt}
    In their 2015 Paper \citetitle{Rhodin:2015} \cite{Rhodin:2015} Rhodin \etal describe a volumetric image formation
    model based on a parametric density representation $D(\mathbf{x})$ defined by a sum of scaled isotropic guassians
    $\mathcal{G} = \{ G_q \}_q$. The density $D$ is then given as
    \begin{align}
        D(\mathbf{x}) &= \sum_{G_q \in \mathcal{G}} G_q(\mathbf{x})
        \label{eq:density}\\
        \text{with} \nonumber\\
        G_q(\mathbf{x}) &= c_q \cdot \exp{\left( - \frac{\Vert\mathbf{x} - \mu_q\Vert_2^2}{2\sigma_q^2} \right)}
        \label{eq:gaussian}
    \end{align}
    where $c_q$ describes the magnitude, $\mu_q$ the center and $\sigma_q$ the standard deviation of the Gaussian $G_q$.
    Additionally, an \gls{albedo} attribute $\mathbf{a}_q$ is defined for each Gaussian to denote its color. This leads
    to the scene representation $\gamma = \{ c_q, \mu_q, \sigma_q, \mathbf{a}_q \}$. The $\gamma$ is omitted from
    $G_q(\mathbf{x})$ for readability and since the parameters are given implicitly via $q$.

    To get the final color of a pixel they determine the amount of light that reaches the camera from each point
    along a ray. For this purpose they determine the \gls{transmittance} $T$ of a point at distance $s$ along a ray from
    a camera position $\mathbf{o}$ in direction $\mathbf{n}$ as
    \begin{equation}
        T(\mathbf{o}, \mathbf{n}, s, \gamma) = \exp{\left( - \int_0^s D(\mathbf{o} + t\mathbf{n}) dt \right)}.
        \label{eq:transmittance}
    \end{equation}

    For the Gaussian density representation the density along a ray $\mathbf{x} = \mathbf{o} + s\mathbf{n}$ through a
    sum of 3D Gaussians is a sum of 1D Gaussians, where the 1D Gaussians are given by inserting the ray into the
    3D Gaussians $G_q$ \eqref{eq:gaussian}. This results in the form
    $\bar{c} \exp{\left( - \frac{(x - \bar{\mu})^2}{2\bar{\sigma}^2} \right)}$ for the 1D scaled Gaussians, with
    $\bar{\mu} = (\mu - \mathbf{o})^T\mathbf{n}$, $\bar{\sigma} = \sigma$ and
    $\bar{c} = c \cdot \exp{\left( - \frac{(\mu - \mathbf{o})^T(\mu - \mathbf{o}) - \bar{\mu}^2}{2\bar{\sigma}^2} \right)}$.

    The \gls{transmittance} can be expressed analytically using the error function
    $\erf{(x)} = \frac{2}{\sqrt{\pi}}\int_0^s \exp{(-t^2)} dt$ and Gaussian form of the density, as
    \begin{equation}
        \begin{aligned}
            T(\mathbf{o}, \mathbf{n}, s, \gamma) &= \exp{\left( -\int_0^s
                \sum_q G_q(\mathbf{o} + t\mathbf{n} ) dt \right)}\\
            &= \exp{\left( \sum_q \frac{\bar{\sigma}_q \bar{c}_q}{\sqrt{\frac{2}{\pi}}}
            \left( \erf{\left( \frac{-\bar{\mu}_q}{\sqrt{2}\bar{\sigma}_q} \right)}
            - \erf{\left( \frac{s - \bar{\mu}_q}{\sqrt{2}\bar{\sigma}_q} \right)} \right) \right)}.\\
        \end{aligned}
        \label{eq:transmittance_analytical}
    \end{equation}

    Assuming the elements in the scene emit an equal amount of \gls{radiance}, a ray is shot through each pixel of a virtual
    \gls{pinhole_camera}. The \gls{radiance} can be computed as the product of \gls{transmittance} $T$ \eqref{eq:transmittance},
    density $D$ \eqref{eq:density}, \gls{albedo} $\mathbf{a}$ and the ambient \gls{radiance} $L_e$ integrated along a ray
    $\mathbf{x} = \mathbf{o} + s\mathbf{n}$. They assume the ambient \gls{radiance} is fixed as $L_e = 1$. As such they
    disregard it in
    \begin{equation}
        L(\mathbf{o}, \mathbf{n}, \gamma) = \int_0^\infty T(\mathbf{o}, \mathbf{n}, s, \gamma)
            \sum_q G_q(\mathbf{o} + s\mathbf{n})\mathbf{a}_q ds.
    \end{equation}
    
    This integral may be approximated with sufficient accuracy by sampling around the mean of each Gaussian $G_q$
    a compact interval $S_q = \{ \bar{\mu}_q + k\lambda_q | k \in K \subset \Z \}$. For their purposes it was sufficient
    to choose $\lambda_q \sim \bar{\sigma}_q$ as the step length, which yields
    \begin{equation}
        \hat{L}(\mathbf{o}, \mathbf{n}, \gamma) = \sum_q \mathbf{a}_q \sum_{s \in S_q}
            \lambda_q T(\mathbf{o}, \mathbf{n}, s, \gamma)G_q(\mathbf{o} + s\mathbf{n}).
        \label{eq:radiance}
    \end{equation}

    Rhodin \etal describe that local sampling with $\lambda_q = \bar{\sigma}_q$ and
    $K = \{ -4, -3, \dots, 0 \}$ delivers a good enough approximation.

    \section{Gaussian Splatting}
    %@TODO: describe image formation model (splatting) as laid out in the following papers
    Gaussian splatting is an image formation model first described by \citeauthor{splatting} in \enquote{\citetitle{splatting}}
    (\citeyear{splatting}) \cite{splatting}. The method works, like classic mesh based rasterization methods, by projecting
    Gaussians, ordered by their depth, onto the image plane. Derivatives of the method are still used in computer vision and graphics
    contexts, since its fully differentiable and its applicability in real time contexts.

    One of these derived methods is called 3D Gaussian splatting and was introduced by \citeauthor{kerbl3Dgaussians} in their
    \citeyear{kerbl3Dgaussians} paper \citetitle{kerbl3Dgaussians}\cite{kerbl3Dgaussians}. \citeauthor{splatting} define their Gaussians
    as 4-tuples $(\mu, \Sigma, \mathbf{a}, \alpha)$, where $\mu \in \R^3$ is the mean of the Gaussian, $\Sigma \in \R^{3\times 3}$
    its 3D covariance Matrix, $\mathbf{a} \in [0, 1]^3$ its albedo and $\alpha \in [0, 1]$ its opacity. The camera is defined as a tuple
    $(W, P)$, where $W$ is the viewing transformation and $P$ is the affine projective transformation.

    To project the 3D covariance matrix to a 2D covariance matrix they employ a method described by \citeauthor{volume_splatting}
    in \citetitle{volume_splatting}\cite{volume_splatting}. A covariance matrix $\Sigma'$ in camera coordinates can be computed
    from the viewing transformation $W$ as:
    \begin{equation}
        \Sigma' = JW\Sigma W^TJ^T
    \end{equation}
    with $J$ as the jacobian of $P$ at $\mu$. \citeauthor{kerbl3Dgaussians} cite that \citeauthor{volume_splatting} also show that discarding the third row and column yields
    a 2D covariance matrix $\Sigma_{2D}$.

    \begin{itemize}
        \item back to front projection
        \item alpha blending
    \end{itemize}

    \section{Ray Tracing vs. Splatting}
    %@TODO: What differentiates the two methods? Advantages? Disadvantages?

    \chapter{Optimizations}
    \label{ch:optimizations}
    %@TODO: Write introductory paragraph on optimizations
    I propose two optimizations to make execution of the method proposed by \citeauthor{Rhodin:2015}
    in \cite{Rhodin:2015} on the CPU possible with greatly reduced runtimes.
    The first optimization is vectorization (\ref{sec:vectorization}) of the method
    parallelizing part of its calculations.
    The second optimization is tiling (\ref{sec:tiling}) which reduces the number of Gaussians
    that have to be processed per pixel.

    \section{Vectorization}
    \label{sec:vectorization}
    Vectorization, describes applying some function or operation usually applied to a scalar value
    to multiple values - a vector - in parallel.
    It is usually applied to reduce the number of operations necessary to finish some task that
    requires the application of some function on a large list of values.

    Take summing up a list $L$ of $N$ values as an example. Usually this requires $N - 1$ additions.
    Applying vectorization with a vector length of $W$ I can divide $L$ into $\lceil \frac{L}{W} \rceil$
    batches of $W$ values each, padding the last one with zeros in case $|L| \mod W \not\equiv 0$. Now I
    can get the same sum by first adding up the batches and then summing up the values in the resulting
    vector. This requires $\lceil \frac{N}{W} \rceil + W - 2 \leq N - 1$ additions.

    \subsection{Notation}
    Since the method as it is laid out in \cite{Rhodin:2015} makes use of conventional vectors it is
    necessary to introduce some notation to work with vectorization and ensure it is
    cleanly separated from conventional vector spaces. Vectors used for parallelization
    will be referred to as p-vectors (parallel vectors) from here on. This notation is
    defined in Table~\ref{tab:notation}.
    \begin{table}[b]
        \centering
        \rowcolors{1}{white}{lightgray}
        \begin{tabular}{|c|c|}
            \hline
            Notation & Definition \\
            \hline
            $x^W$ & p-vector containing $W$ elements\\
            $x^W_i$ & $i$-th element of p-vector $x$\\
            $\mathbf{x}^W$ & p-vector containing $W$ vectors $\mathbf{x} \in \R^n$\\
            $\langle \mathbf{x}^W, \mathbf{y}^W \rangle$ & elementwise inner product of the vectors in $\mathbf{x}$ and $\mathbf{y}$\\
            $[ x ]^W$ & $x$ broadcast to a p-vector of $W$ elements\\
            $\odot$ & elementwise multiplication\\
            $\frac{x^W}{y^W}$ & elementwise division\\
            $f^W$ & function that produces a p-vector containing $W$ elements\\\hline
        \end{tabular}
        \caption{Vectorization Notation}
        \label{tab:notation}
    \end{table}

    \subsection{Approaches}
    There are multiple ways to parallelize Gaussian ray tracing using vectorization. To generate the final image it is necessary to iterate
    over two quantities: (1) the Gaussians in the scene and (2) the pixels of the image. Therefore, these are the opportunities to parallelize.
    Parallelism over the pixels is possible by expanding the rendering equations given in \cite{Rhodin:2015} to operate on multiple rays at the
    same time. Parallelism over the Gaussians is possible in two ways:
    \begin{enumerate}
        \item The summands of the sum in the \gls{transmittance} equation~\eqref{eq:transmittance_analytical} do not depend on each
            other therefore it is possible to divide the summands into equal groups and process these in parallel
            and add these results up in the end to get the final result.
        \item The same principle can be applied to the outer sum in the \gls{radiance} equation~\eqref{eq:radiance}: the summands are
            not dependent on each other therefore they can be divided into equal groups that can
            be processed in parallel and added up in the end to get the final \gls{radiance}.
    \end{enumerate}
    The inner sum of the \gls{radiance} equation~\eqref{eq:radiance} is not interesting, in terms of parallelism, since the number
    of summands it has is fixed and therefore potential runtime improvements would not scale with the width of the p-vectors used, and
    it is fair to assume that most methods of vectorization will allow for p-vectors wider than five elements.

    To enable parallelization over the Gaussians it is necessary to split the set of
    Gaussians $\mathcal{G}$ into $W$ disjoint subsets of equal magnitude. Since the magnitude of $\mathcal{G}$ is not guaranteed to be divisible by $W$
    a number of subsets equal to the remainder $|\mathcal{G}| \mod W$ will be augmented with an additional zero element.

    The most sensible division of $\mathcal{G}$ is to assign some order to its elements, such that $g_i, i=1,\dots,|\mathcal{G}|$ describes the $i$-th element of
    $\mathcal{G}$. With this $\mathcal{G}$ can be divided into subsets $\mathcal{G}_j$ with
    \begin{equation}
        \mathcal{G}_j := \{ g_i \in \mathcal{G} \,|\, i \mod W \equiv j \} \text{ for } j=0,\dots,W-1.
    \end{equation}

    \paragraph{Parallel \gls{transmittance}:}
    \label{par:parallel_transmittance}
    Given this division I can define a \gls{transmittance} function
    \begin{equation}
        \begin{aligned}
            T^W(\mathbf{o}, \mathbf{n}, s, \gamma) &= \exp^W\left( \sum_{m = 0}^{\left\lceil \frac{|\mathcal{G}|}{W} \right\rceil - 1}
            \begin{pmatrix}
                \frac{\bar{\sigma}_{mW}\bar{c}_{mW}}{\sqrt{\frac{2}{\pi}}} \\ \vdots \\\frac{\bar{\sigma}_{(m+1)W-1}\bar{c}_{(m+1)W-1}}{\sqrt{\frac{2}{\pi}}} 
            \end{pmatrix} \right.\\&\left.\odot \begin{pmatrix}
                \erf{\left( \frac{- \bar{\mu}_{mW}}{\sqrt{2}\bar{\sigma}_{mW}} \right) - \erf{\left( \frac{s - \bar{\mu}_{mW}}{\sqrt{2}\bar{\sigma}_{mW}} \right)}} \\
                \vdots \\
               \erf{\left( \frac{- \bar{\mu}_{(m+1)W - 1}}{\sqrt{2}\bar{\sigma}_{(m+1)W - 1}} \right) - \erf{\left( \frac{s - \bar{\mu}_{(m+1)W - 1}}{\sqrt{2}\bar{\sigma}_{(m+1)W - 1}} \right)}} 
            \end{pmatrix}\right)
        \end{aligned}
        \label{eq:transmittance_parallel}
    \end{equation}
    that operates on the elements of the subsets $\mathcal{G}_j$ in parallel.

    Note that the separation of the Gaussians into the subsets $\mathcal{G}_j$ is done implicitly through the index $m$ of the sum.

    Now I replace the call to the \gls{transmittance} function in the \gls{radiance} equation~\eqref{eq:radiance} with the sum
    over the results of the parallel \gls{transmittance} equation~\eqref{eq:transmittance_parallel} yielding
    \begin{equation}
        \hat{L}(\mathbf{o}, \mathbf{n}, \gamma) = \sum_{q} \mathbf{a}_q \sum_{s \in S_q} \lambda_qG_q(\mathbf{o} + s\mathbf{n})\sum_{i = 1}^W T^W_i(\mathbf{o}, \mathbf{n}, s, \gamma).
    \end{equation}

    Since the subsets $\mathcal{G}_j$ are disjoint by definition this version of the \gls{radiance} equation yields the same results as the original (Eq.~\eqref{eq:radiance})

    \paragraph{Parallel \gls{radiance}:}
    \label{par:parallel_radiance}
    The analytical solution to the \gls{transmittance} integral from Eq.~\eqref{eq:transmittance_analytical} can be broadcast
    to
    \begin{equation}
        \begin{aligned}
            T^W(\mathbf{o}^W, \mathbf{n}^W, s^W, \gamma) = \exp^W\Bigg(& \sum_q \frac{(\bar{\sigma}_q)^W
            (\bar{c}_q)^W}{\left[ \sqrt{\frac{2}{\pi}} \right]^W} \\
            \odot \Bigg(& \erf^W{\left( \frac{-(\bar{\mu}_q)^W}{[ \sqrt{2} ]^W \odot (\bar{\sigma}_q)^W} \right)}\\
            &- \erf^W{\left( \frac{s^W - (\bar{\mu}_q)^W}{[ \sqrt{2} ]^W \odot (\bar{\sigma}_q)^W} \right)} \Bigg) \Bigg)
        \end{aligned}
        \label{eq:transmittance_broadcast}
    \end{equation}
    operating on p-vectors of points on rays parameterized by origins $\mathbf{o}^W$, directions $\mathbf{n}^W$
    and distances $s^W$ with
    \begin{align*}
        \bar{\mu}^W &= \left\langle [ \mu ]^W - \mathbf{o}, \mathbf{n}^W \right\rangle, \bar{\sigma}^W = \left[ \sigma \right]^W\\
        \bar{c}^W &= [c]^W \odot \exp^W{\left( - \frac{\left\langle [\mu]^W - \mathbf{o}^W, [\mu]^W - \mathbf{o}^W \right\rangle
    - \left(\bar{\mu}^W\right)^2}{[2]^W \odot \left(\bar{\sigma}^W\right)^2} \right)}.
    \end{align*}

    This version of the \gls{transmittance} equation \eqref{eq:transmittance_analytical} allows me to rewrite the \gls{radiance} equation
    \eqref{eq:radiance} to operate on multiple Gaussians at the same time in the same way as in \ref{par:parallel_transmittance}
    \begin{equation}
        \begin{aligned}
            \hat{L}^W(\mathbf{o}, \mathbf{n}, \gamma) &= \sum_{m = 0}^{\left\lceil \frac{|\mathcal{G}|}{W} \right\rceil - 1} \left( \begin{pmatrix}
                \mathbf{a}_{mW}\\ \vdots \\ \mathbf{a}_{(m+1)W - 1}
            \end{pmatrix} \right.\\
            &\odot \sum_{s^W \in S_m} \left( T^W([\mathbf{o}]^W, [\mathbf{n}]^W, s^w, \gamma)\right.\\
            &\odot \left.\left.\begin{pmatrix}
                G_{mW}(\mathbf{o} + s^W_1\mathbf{n})\\ \vdots\\ G_{(m+1)W - 1}(\mathbf{o} + s^W_W\mathbf{n})
            \end{pmatrix}\right)\right)
        \end{aligned}
        \label{eq:radiance_parallel_gaussians}
    \end{equation}
    with
    \[ S_m = \left\{\left. \begin{pmatrix}
        \bar{\mu}_{mW}\\ \vdots\\ \bar{\mu}_{(m+1)W - 1}
    \end{pmatrix} + [k]^W \odot \begin{pmatrix}
        \lambda_{mW}\\ \vdots\\ \lambda_{(m+1)W - 1}
    \end{pmatrix} \,\right|\, k \in K \subset \Z \right\} \]
    and $\bar{\mu}$, $\bar{\sigma}$ and $\bar{c}$ defined the same as in Section~\ref{sec:int_grt}.

    Finally, we can collect these results into the \gls{radiance}
    \begin{equation}
        \hat{L}(\mathbf{o}, \mathbf{n}, \gamma) = \sum_{i = 1}^W \hat{L}^W_i(\mathbf{o}, \mathbf{n}, \gamma).
        \label{eq:radiance_parallel_final}
    \end{equation}

    \paragraph{Parallel Pixels:}
    \label{par:parallel_pixels}
    Given the broadcast version of the \gls{transmittance} equation \eqref{eq:transmittance_broadcast} from before I can broadcast the \gls{radiance} equation to
    calculate the \gls{radiance} for multiple pixels at once:
    \begin{equation}
        \begin{aligned}
            \hat{L}^W(\mathbf{o}^W, \mathbf{n}^W, \gamma) &= \sum_q [ \mathbf{a}_q ]^W \sum_{s \in S_q} \Big(
            [ \lambda_q ]^W \odot T^W(\mathbf{o}^W, \mathbf{n}^W, [ s ]^W, \gamma)\\
            &\odot G_q^W(\mathbf{o}^W + [ s ]^W \odot \mathbf{n}^W) \Big)
        \end{aligned}
        \label{eq:radiance_parallel_pixels}
    \end{equation}

    Note that both the \gls{transmittance} and \gls{radiance} equations still operate on the Gaussians one by one as the
    sums iterate over every Gaussian $G_q \in \mathcal{G}$ individually.

    \section{Tiling}
    \label{sec:tiling}
    %@TODO: describe the tiling method used. note similarities to splatting.
    In most scenes most pixels will be unaffected by most Gaussians, therefore it is not sensible to perform
    the per pixel calculations for all Gaussians instead of just the Gaussians that could affect the pixel.
    Reducing the number of Gaussians considered when dealing with any individual pixel is a good way to reduce
    time wasted performing unnecessary computations.

    \begin{figure}[t]
        \centering
        \resizebox{\textwidth}{!}{
            \begin{tikzpicture}
                \draw[gray, thin] (0, 0) grid[xstep=4, ystep=2.25] (16, 9);

                \fill[purple] (12, 5.5) circle (0.1);
                \draw[purple, thick] (12, 5.5) circle (3);

                \fill[red] (2.7, 1.8) circle (0.1);
                \draw[red, thick] (2.7, 1.8) circle (1.7);
                
                \fill[green] (4, 3) circle (0.1);
                \draw[green, thick] (4, 3) circle (1.5);
                
                \fill[blue] (5, 2) circle (0.1);
                \draw[blue, thick] (5, 2) circle (1);
            \end{tikzpicture}
        }
        \caption{Image of four Gaussians split into 16 tiles.}
        \label{fig:tiling}
    \end{figure}

    One way of achieving this goal is to split the final image into $N \times N$ tiles (\eg Figure~\ref{fig:tiling}) and determining which Gaussians
    are relevant to which tiles through spacial proximity. Since it is not clear where in the image any one Gaussian is
    going to end up before generating the image it is necessary to estimate location and size of the Gaussians before
    generating the final image through ray tracing.

    To estimate size and position of the Gaussians in the final image the guassians are projected to the image plane using
    scaled orthographic projection. Let $V \in \R^{4 \times 4}$ be the view matrix of the camera. Then the projected guassian
    $\bar{g} = (\bar{\mu}, \bar{\sigma})$ to a Gaussian $g = (\mu, \sigma)$ is calculated as:

    \begin{align}
        \mu_p &= V \cdot (\mu, 1)^T\\
        \bar{\mu} &= \frac{1}{\mu_{p3}} \cdot (\mu_{p1}, \mu_{p2})^T\\
        \bar{\sigma} &= \frac{\sigma}{\mu_{p3}}
    \end{align}

    Note that this method of projection is a simplified version of the projection used in \cite{kerbl3Dgaussians}, since I only consider isotropic Gaussians which removes
    the complexity of projecting the covariance matrix while retaining its properties.
    As in \cite{Rhodin:2015} Gaussians with $\bar{\sigma} < 10^{-5}$ are discarded, since they are unlikely to contribute to the final image significantly.
    Also note that after the projection the image coordinates are mapped to $[-1, 1] \times [-1, 1]$.

    Let $tw, th \in \R$ be the width and height of a tile and let $\mathbf{c} \in \R^2$ denote the center of the tile. The vector $\mathbf{p} = (|\mathbf{c}_1 - \bar{mu}_1|, |\mathbf{c}_2 - \bar{\mu}_2|)^T$
    describes the absolute distances along the $x$ and $y$ Axes between the center of the tile $\mathbf{c}$ and mean of the projected Gaussian $\bar{\mu}$.
    A Gaussian counts as relevant to a tile if
    \begin{equation}
        \mathbf{p}_1 < |\mathbf{c}_1| + \frac{tw}{2} + 2\bar{\sigma}
    \end{equation}
    and 
    \begin{equation}
        \mathbf{p}_2 < |\mathbf{c}_2| + \frac{th}{2} + 2\bar{\sigma}
    \end{equation}
    meaning that the Gaussian has to be in a $2\bar{\sigma}$ range from the borders of the tile to be considered relevant.
    The $|\mathbf{c}_i|, i=1,2$ terms are added to account for stronger perspective distortion towards the edges of the image.

    \chapter{Approximations}
    \label{ch:approximations}
    %@TODO: Explain why it is necessary to approximate functions / implement own approximations
    \section{Cubic Spline Interpolation}
    %@TODO: Describe cubic spline interpolation

    \section{Fast Exponential Function}
    \cite{fast_exp}
    \begin{equation}
        \exp{(x)} = 2^{\frac{x}{\ln{(2)}}}
    \end{equation}
    
    \section{Polynomial Approximations of the Error Function}
    \subsection{Taylor Series}
    The Taylor series of the error function is given as:
    \begin{equation}
        \erf{(x)} = \frac{2}{\sqrt{\pi}} \sum_{n = 0}^\infty \frac{x}{2n + 1} \prod_{k = 1}^n \frac{-x^2}{k}
    \end{equation}
    \subsection{Abramowitz and Stegun}
    \citeauthor{AbraSteg72} give one such approximation in Section 7.1.27 of their \enquote{\citetitle{AbraSteg72}}\cite{AbraSteg72} as:
    \begin{equation}
        \erf{(x)} = 1 - \frac{1}{(1 + ax + bx^2 + cx^3 + dx^4)^4}
    \end{equation}
    with
    \begin{align*}
        a &= 0.278393,\,
        b = 0.230289\\
        c &= 0.000972,\,
        d = 0.078108
    \end{align*}
    
    \chapter{Implementation}
    \label{ch:implementation}
    %@TODO: details TBD
    I implemented Gaussian ray tracing as described in Section~\ref{sec:int_grt} with the optimizations described in Chapter~\ref{ch:optimizations} in C++. For this I utilized the \gls{simd}
    instructions provided by modern x64 CPUs (\ref{sec:simd}) to implement vectorization (\ref{sec:vectorization}) along with a thread pool (\ref{sec:thread_pool}) to further increase
    the performance gained from the tiling (\ref{sec:tiling}).

    The Implementation is split into two parts: (1) a library that implements the rendering functions, tiling and approximations and (2) a renderer that uses the library to generate images.

    The source code of the implementation is available at: \href{https://github.com/Sebastian-Dawid/simd-gaussian-ray-tracing}{https://github.com/Sebastian-Dawid/simd-gaussian-ray-tracing}

    \section{SIMD}
    \label{sec:simd}
    \gls{simd} (Single Instruction Multiple Data) is a type of parallelism available in most modern x64 and ARM CPUs. This form of parallelism is made available in the form of CPU instructions
    that operate on special vector registers that are characterized by their width. For example a x64 CPU might provide registers that are 256 bits wide instead of the usual
    register width of 64 bits on x64 CPUs.
    
    Which instructions and which register width a CPU supports depend on which extensions to the instruction set are available on that CPU.

    \gls{simd} instructions are usable from C/C++ code through intrinsics. Which intrinsics are available based on the available instruction set extensions
    can be referenced in the \href{https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html}{Intel Intrinsics Guide}\footnote{https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html}.
    Using instrinsics directly has the disadvantage that the code is tied to the extension that makes those intrinsics available. Therefore, I opted to use a wrapper library (\ref{sec:tsimd})
    to avoid direct usage of intrinsics.

    \subsection{Math to SIMD}
    \begin{itemize}
        \item most conversion are 1 to 1
        \item p-vectors of vectors are implemented as vectors of p-vectors
    \end{itemize}
    \subsection{T-SIMD}
    \label{sec:tsimd}
    A simple way to make the code compatible with different \gls{simd} extensions is the T-SIMD library described in \enquote{\citetitle{own_moeller_16_2}} \cite{own_moeller_16_2} by \citeauthor{own_moeller_16_2}.

    \section{Library}
    \subsection{Approximations}
    I implemented the approximations described in Chapter~\ref{ch:approximations} and provide wrappers for approximations from Intel's Short Vector
    Math Library (\ref{sec:svml}) and Agner Fogs Vector Class Library (\ref{sec:vcl}).
    \subsubsection{Short Vector Math Library (SVML)}
    \label{sec:svml}
    Intel's SVML provides implementations for both the exponential and error functions. Since the library is closed source I have no way of knowing how these approximations were implemented.
    I export the symbols for the AVX2 (\mintinline{c}{__svml_expf8}) and AVX512 (\mintinline{c}{__svml_expf16}) versions of the implementations as part of the \mintinline{c++}{approx}
    namespace along with a template wrapper function that is instantiated for the vector widths available (see Listing~\ref{lst:template_svml_exp}).

    \begin{listing}[H]
        \begin{minted}[linenos, frame=lines]{c++}
template<size_t SIMD_WIDTH>
inline simd::Vec<simd::Float, SIMD_WIDTH>
svml_exp(simd::Vec<simd::Float, SIMD_WIDTH> x);

#ifdef __AVX2__
template<>
inline simd::Vec<simd::Float, 32>
svml_exp(simd::Vec<simd::Float, 32> x);
{
    return __svml_expf8(x);
}
#endif

#ifdef __AVX512F__
template<>
inline simd::Vec<simd::Float, 64>
svml_exp(simd::Vec<simd::Float, 64> x);
{
    return __svml_expf16(x);
}
#endif
        \end{minted}
        \caption{Template wrapper for SVML's exponential function.}
        \label{lst:template_svml_exp}
    \end{listing}

    \subsubsection{Vector Class Library (VCL)}
    \label{sec:vcl}
    The approximation of the exponential function provided by VCL is based on the IEEE-754 single precision floating point format and the Taylor series of the exponential function.
    I provide wrapped versions of the approximation in the same way shown in Listing~\ref{lst:template_svml_exp} to deal with the conversion between the T-SIMD and VCL vector types.

    \subsection{Thread Pool}
    \label{sec:thread_pool}
    As part of the library I implemented a simple thread pool to provide multithreaded versions of the rendering functions (\ref{sec:rendering_functions}).
    The pool provides a queue into which tasks are submitted. When a new task is submitted a waiting thread of the pool, if available, is notified.
    All interactions with the queue are protected through a scoped \mintinline{c++}{std::unique_lock<std::mutex>}.

    \begin{listing}[H]
        \begin{minted}[linenos, frame=lines]{c++}
struct thread_pool_t
{
    std::contion_variable cond;
    std::mutex queue_mutex;
    std::queue<std::function<void()>> tasks;
    std::vector<std::thread> threads;
    bool stopped = false;

    thread_pool_t(size_t thread_count);
    void enqueue(std::function<void()> task);
    ~thread_pool_t();
};
        \end{minted}
        \caption{Interface of the thread pool}
        \label{lst:thread_pool_interface}
    \end{listing}

    The pool implements the interface shown in Listing~\ref{lst:thread_pool_interface}.
    The pool is initialized with \mintinline{c++}{thread_cont} threads. The threads are joined when the pool's destructor is called either through the end of the scope when
    used as a stack object or smart pointer or the \mintinline{c++}{delete} operator in case of a heap object.

    The threads execute the following steps: (1) claim the pool's mutex, (2) wait for the condition variable to be signaled if no tasks are available and the pool
    has not been stopped, (3) exit if the pool has been stopped and there are no more tasks in the queue, (4) dequeue a task from the queue, (5) release the mutex, (6) execute
    the task and return to (1).

%     \begin{listing}[H]
%         \begin{minted}[linenos, frame=lines]{c++}
% while (true)
% {
%     std::function<void()> task;
%     {
%         std::unique_lock<std::mutex> lock(queue_mutex);
%         cond.wait(lock, [this](){
%             return !tasks.empty() || stopped; });
%         if (stopped && tasks.empty()) return;
%         task = std::move(tasks.front());
%         tasks.pop();
%     }
%     task();
% }
%         \end{minted}
%         \caption{Code executed by threads in pool}
%         \label{lst:thread_code}
%     \end{listing}

    \subsection{Rendering Functions}
    \label{sec:rendering_functions}
    \section{Renderer}
    \label{sec:renderer}
    \begin{table}[H]
        \centering
        \rowcolors{1}{white}{lightgray}
        \begin{tabular}{|c|c|}
            \hline
            Mode & Features\\
            1    & Sequential Baseline\\
            2    & Parallel \gls{transmittance}\\
            3    & Parallel \gls{radiance}\\
            4    & Parallel Pixels\\
            5    & Sequential + Tiling\\
            6    & Parallel \gls{transmittance} + Tiling\\
            7    & Parallel \gls{radiance} + Tiling\\
            8    & Parallel Pixels + Tiling\\
            st   & Single Threaded\\
            mt   & Multi Threaded\\
            \hline
        \end{tabular}
        \caption{Modes}
        \label{tab:exec_modes}
    \end{table}
    
    \chapter{Experiments}
    \label{ch:experiments}
    \section{Approximations}
    \section{Transmittance}
    \section{Full Render}
    Aside from testing singular functions or sections of the program, I have also performed a number of end-to-end tests
    to evaluate the performance improvements of the implemented optimizations in a, close to, real world scenario.
    The tests will be performed on two separate models and evaluate different aspects of the implementation,
    which I will describe in the following sections:
    \subsection{Utah/Newell Teapot}
    %@TODO: Rerun HPCTOOLKIT tests using Utah Newell Teapot instead of Dense Cube
    \href{https://graphics.stanford.edu/courses/cs148-10-summer/as3/code/as3/teapot.obj}{Model}\footnote{https://graphics.stanford.edu/courses/cs148-10-summer/as3/code/as3/teapot.obj}
    Measure vector instruction waste, efficiency and cache effects

    \begin{figure}[H]
        \centering
        \includegraphics[scale=.2]{images/teapot.png}
        \caption{Teapot rendered using renderer from Section~\ref{sec:renderer}}
        \label{fig:teapot_render}
    \end{figure}

    \subsection{Dense Cube}
    Runtime averaged over 10 frames
    \begin{figure}[H]
        \centering
        \includegraphics[scale=.2]{images/cube.png}
        \caption{Dense cube rendered using renderer from Section~\ref{sec:renderer}}
        \label{fig:cube_render}
    \end{figure}
    
    \chapter{Results and Discussion}

    The results of the experiments discussed in Chapter~\ref{ch:experiments} show

    \section{Runtime}

    On average the runtime is reduced by $19\%$ when compiling with clang instead of GCC.
    Rendering finishes about $9.4$ times faster when using tiling.

    Figure~\ref{fig:runtimes_st_simd_speedup} shows
    the speedups gained from employing the \gls{simd} routines described in Chapter~\ref{ch:optimizations}
    and Chapter~\ref{ch:implementation}. Showing a speedup of up to $25$ times when
    parallelization over the images pixels.
    \begin{figure}[H]
        \centering
        \input{plots/simd_speedup}
        \caption{Single Threaded Speedups from using SIMD}
        \label{fig:runtimes_st_simd_speedup}
    \end{figure}

    While the SVML routines provide much higher accuracy using them is not worth the
    performance trade-off as seen in Figure~\ref{fig:runtimes_st_svml_v_no}.
    \begin{figure}[H]
        \centering
        \input{plots/runtimes_svml}
        \caption{Single Threaded Runtimes using SVML and no SVML with Clang}
        \label{fig:runtimes_st_svml_v_no}
    \end{figure}

    \begin{figure}[H]
        \centering
        \input{plots/speedup}
        \caption{Speedup of Modes 6-8 relative to Mode 5}
        \label{fig:runtimes_st_v_mt}
    \end{figure}

    \section{HPCTOOLKIT}
    \cite{hpc_toolkit}

    The derived metrics used were vector instruction waste and vector instruction efficiency defined as:
    \begin{align}
        \text{waste}(\text{cycles}, \text{instructions}) = 2 \cdot \text{cycles} - \text{instructions} \label{eq:vec_waste}\\
        \text{efficiency}(\text{cycles}, \text{instructions}) = 100 \cdot \frac{\text{instructions}}{2\cdot\text{cycles}} \label{eq:vec_efficiency}
    \end{align}
    which should be based on the exclusive\footnote{An exclusive metric refers to the quantity of the metric measured for that scope
    alone, disregarding nested scopes such as function calls. Reference: HPCTOOLKIT User Manual page 18
    \href{https://hpctoolkit.org/manual/HPCToolkit-users-manual.pdf}{https://hpctoolkit.org/manual/HPCToolkit-users-manual.pdf}}
    \mintinline{c}{PAPI_TOT_CYC} (total cycles) and \mintinline{c}{PAPI_VEC_INS}
    (vector instructions) metrics for the given scopes. HPCToolkit does not include inlined functions in exclusive metrics, which is why \gls{simd}
    instructions and CPU cycles generated by the T-SIMD library would not count towards the exclusive \mintinline{c}{PAPI_VEC_INS} and \mintinline{c}{PAPI_TOT_CYC}
    metrics.

    \begin{listing}[H]
        \begin{minted}[linenos, frame=lines]{c++}
f32 func(f32 in)
{
    // inlined broadcast should count for scope
    simd::Vec<simd::Float> x = simd::set1(in);
    // exp should not count for scope
    x = simd::exp(x);
    // inlined mul and broadcast should count for scope
    x = x * simd::set1(2.f);
    return x;
}
        \end{minted}
        \caption{Example for functions calls that should and should not count towards exclusive metrics.}
        \label{lst:scopes_example}
    \end{listing}

    As such the inclusive metrics are used for calculating the derived metrics. To get the exclusive derived metrics including the inlined T-SIMD functions I subtract
    the inclusive derived metrics of the functions I want to disregard. For the example in Listing~\ref{lst:scopes_example}
    this would be:
    \[ \text{metric}_e = \text{metric}_i - \text{metric}_{\text{simd::exp}} \]
    where $\text{metric}_i$ is the inclusive metric and $\text{matric}_{\text{simd::exp}}$ is the metric for the \mintinline{c++}{simd::exp} call.

    %Therefore the derived metrics are calculated using the inclusive metrics. To obtain the final value for the derived metrics the
    %value of the derived metrics of the scopes of non T-SIMD functions are subtracted from the value calculated using the inclusive metrics.

    \chapter{Conclusion and Future Work}
    %@TODO: Short recap + what can still be done: anisotropic Gaussians, loading models learned via Gaussian splatting, more efficient tiling method using SIMD, performance left on the table TBD (see results)
    \section{Conclusion}
    \begin{itemize}
        \item SIMD + Tiling lead to massive performance improvements
    \end{itemize}

    \section{Future Work}
    \begin{itemize}
        \item Memory/Cache Bottleneck?
        \item Anisotropic Gaussians
        \item Loading Scenes learned via Gaussian splatting
        \item More efficient tiling (SIMD, Threads)
        \item Combining Splatting and Ray Tracing
        \item GPU Implementation
    \end{itemize}

    \appendix
    \chapter{Tables}
    \label{ch:tables}
    \begin{table}[H]
        \centering
        \rowcolors{1}{white}{lightgray}
        \begin{tabular}{|c | c | c | c|}
            \hline
            Mode & GCC               & Clang & SVML\\\hline
            1 st & $\sim1648.17$ sec & $\sim1373.29$ sec & - \\
            2 st & $\sim96.47$ sec   & $\sim82.86$ sec   & $\sim150.08$ sec\\
            3 st & $\sim69.44$ sec   & $\sim56.78$ sec   & $\sim134.33$ sec\\
            4 st & $\sim67.19$ sec   & $\sim52.62$ sec   & $\sim136.42$ sec\\
            5 st & $\sim170.74$ sec  & $\sim136.84$ sec  & - \\
            6 st & $\sim11.95$ sec   & $\sim9.69$ sec    & $\sim17.80$ sec\\
            7 st & $\sim7.46$ sec    & $\sim5.83$ sec    & $\sim14.82$ sec\\
            8 st & $\sim7.08$ sec    & $\sim5.61$ sec    & $\sim15.02$ sec\\\hline\hline

            5 mt & $\sim6.60$ sec    & $\sim5.93$ sec    & $\sim5.94$ sec\\
            6 mt & $\sim0.62$ sec    & $\sim0.53$ sec    & $\sim0.95$ sec\\
            7 mt & $\sim0.47$ sec    & $\sim0.40$ sec    & $\sim0.80$ sec\\
            8 mt & $\sim0.45$ sec    & $\sim0.39$ sec    & $\sim0.78$ sec\\
            \hline
        \end{tabular}
        \caption{Runtime of rendering the dense cube based on compiler, SVML usage, and mode using AVX512. Averaged over 10 Frames.}
        \label{tab:perf_dense_cube_avx512}
    \end{table}

    \begin{table}[H]
        \centering
        \rowcolors{1}{white}{lightgray}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            Mode & \gls{radiance}             & \gls{transmittance}          & $\erf$                      & $\exp$\\\hline
            1 st & & & &\\
            2 st & & & &\\
            3 st & & & &\\
            4 st & & & &\\
            5 st & & & &\\
            6 st & & & &\\
            7 st & $3.8 \cdot 10^7$ ($0.9\%$) & $1.15 \cdot 10^9$ ($28.4\%$) & $1.14 \cdot 10^8$ ($2.8\%$) & $4.0 \cdot 10^6$ ($0.1\%$)\\
            8 st & & & &\\\hline\hline
            5 mt & & & &\\
            6 mt & & & &\\
            7 mt & & $3.96 \cdot 10^8$ ($4.4\%$) & &\\
            8 mt & & & &\\
            \hline
        \end{tabular}
        \caption{Clang: Vector Instruction Waste (\% of total) by Mode}
        \label{tab:clang_vec_waste}
    \end{table}
    \begin{table}[H]
        \centering
        \rowcolors{1}{white}{lightgray}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            Mode & \gls{radiance} & \gls{transmittance} & $\erf$   & $\exp$\\\hline
            1 st & & & &\\
            2 st & & & &\\
            3 st & & & &\\
            4 st & & & &\\
            5 st & & & &\\
            6 st & & & &\\
            7 st & $5.0\%$        & $53.78\%$           & $25.0\%$ & - \\
            8 st & & & &\\\hline\hline
            5 mt & & & &\\
            6 mt & & & &\\
            7 mt & & $31.25\%$ & &\\
            8 mt & & & &\\
            \hline
        \end{tabular}
        \caption{Clang: Vector Instruction Efficiency by Mode}
        \label{tab:clang_vec_efficiency}
    \end{table}

    \chapter{Figures}
    \begin{figure}[H]
        \centering
        \input{plots/znver4_simd_erf_timing}
        \caption{Cycles to calculate $n$ values of $\erf$.}
    \end{figure}
    \begin{figure}[H]
        \centering
        \input{plots/znver4_simd_exp_timing}
        \caption{Cycles to calculate $n$ values of $\exp$.}
    \end{figure}
    
    \begin{figure}[H]
        \centering
        \input{plots/znver4_cmp_erf_approx}
        \caption{$\erf$ Approximations}
    \end{figure}
    \begin{figure}[H]
        \centering
        \input{plots/znver4_cmp_erf_err}
        \caption{$\erf$ Errors}
    \end{figure}
    
    \begin{figure}[H]
        \centering
        \input{plots/znver4_cmp_exp_approx}
        \caption{$\exp$ Approximations}
    \end{figure}
    \begin{figure}[H]
        \centering
        \input{plots/znver4_cmp_exp_err}
        \caption{$\exp$ Errors}
    \end{figure}

    \backmatter
    \printglossaries
    \printbibliography[heading=bibintoc]
\end{document}
